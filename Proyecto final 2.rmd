---
nocite: '@*'
output:
  pdf_document: 
    latex_engine: xelatex
  bookdown::pdf_document2:
    fig_caption: yes
---

\thispagestyle{empty} 
\begin {center}


UNIVERSIDAD DE LA REPÚBLICA

Facultad de Ciencias Económicas y de Administración

Licenciatura en Estadística

\vspace{4.5 cm}


\textbf{\large  Análisis explicativo del precio de apartamentos publicados en Airbnb de Barcelona}


\vspace{1.5 cm}

\textbf{Viscailuz, Luciana       Miranda, Germán}\\
\textbf{Junio 2024}


\end{center}


\vspace{3.5cm}

\begin{center}
\textbf{Trabajo final de Modelos Lineales}\\
\vspace{1.0 cm}

\end{center}

\newpage

\renewcommand{\contentsname}{Índice}

\tableofcontents


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.pos = 'H')
```

\newpage 
 
# Introducción

Airbnb es una compañía dedicada a la oferta de alojamientos de carácter vacacional en muchos de los países del mundo. Esta funciona a partir de un programa digital donde los anfitriones pueden publicar sus propiedades para que los clientes puedan verlas y elegir el alojamiento que más se adapte a sus necesidades. 


En este proyecto se trabajó con algunas de las propiedades publidcadas en esta plataforma en la ciudad Barcelona, España. Inicialmente, nuestra motivación del proyecto fue poder estimar el precio (en euros) de diferentes apartamentos según las características de cada uno. Para realizar lo mencionado se trabajó con los datos de Airbnb Barcelona, donde se tenía el registro de más de 16.000 apartamentos de dicha ciudad. 

La información con la que se contaba era buena pero excesiva, lo que llevó a que algunos datos fueran redundantes, por lo cual una parte importante de este proyecto fue la inicial, donde se realizó una limpieza de datos para así disponer de información que permita realizar una buena estimación e interpretación de los datos. 

Finalmente, el trabajo e interpretación de los datos, tanto sobre como actúan entre si y sus diversos efectos sobre la variable de interés fueron los que guiaron y generaron el interés en este proyecto provocando que el paso a paso sea tan importante como el resultado final.  

  

```{r ,echo=FALSE,warning=FALSE,include=FALSE}
library(here)
library(readxl)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(car)
library(qqplotr)
library(skedastic)
library(faraway)
library(knitr)
library(kableExtra)
```

## Los datos

Como se mencionó anteriormente, se disponía de la información de 16.761 apartamentos de Barcelona, donde se nombraban las características que los huéspedes toman en cuenta al momento de elegir su hospedaje y por lo tanto podrían llegar a incidir en su precio, entre estas se destacaba, ubicación, cantidad de camas y baños, cuantas personas se aceptaban, entre otras. 

Habían variables cuantitativas pero la mayoría eran cualitativas, e incluso se pasaron a factor algunas de las cuantitativas para su mejor interpretación. 

La información de código postal y barrio se decidió resumirla en una variable llamada distrito la cual agrupó los 73 barrios de Barcelona en 10 distritos.  

Se decidió prescindir de la latitud y longitud de cada apartamento como de algunas variables que se encontraban dentro de la variable amenities, tomando en cuenta finalmente las diez más #importantes. 

Se definieron dos nuevas variables, "grupo_habitacion" y "grupo_banios", donde se agruparon la cantidad de habitaciones y baños respectivamente, para así disminuir la cantidad de categorías de cada variable.

Del total de observaciones se operó con 12.848 debido a que las restantes contaban con datos faltantes. 

Por último se decicdió trabajar con la transformación logaritmica de la variable respuesta, para así poder solucionar varios problemas relacionados con el diagnóstico que se verá posteriormente.

Finalizada la limpieza y organización de datos se pudo comenzar a trabajar con ellos. 


\newpage 

```{r warning=FALSE,echo=FALSE,tab.cap="Descripción de las variables utilizadas en el informe",fig.align='center', results = 'asis'}
df = read_excel(here("airbnb_barcelona_v2.xlsx"))

df= df %>% select(barrio,
                  tipo_habitacion,
                  personas,
                  banios,
                  habitaciones,
                  camas,
                  precio_euros,	
                  estancia_min,	
                  puntuacion,	 
                  TV,	 
                  Wifi,	
                  Air_conditioning,	
                  Elevator,	
                  Breakfast,	
                  Pets_allowed,	
                  Patio_or_balcony,	
                  check_in_24_hs
                 )%>% filter(is.na(puntuacion)==FALSE,
                                        is.na(barrio)==FALSE,
                                        is.na(banios)==FALSE,
                                        is.na(habitaciones)==FALSE,
                                        is.na(camas)==FALSE
                                        )
            



distritos<-character(length(nrow(df)))
  
for (i in seq_along(df$barrio)) {
    if (df$barrio[i] == "Sant Marta"|| 
               df$barrio[i] == "La Guineueta - Canyelles"|| 
               df$barrio[i] == "La Prosperitat"|| 
               df$barrio[i] == "Nou Barris"|| 
               df$barrio[i] == "Porta"|| 
               df$barrio[i] == "Trinitat Nova"|| 
               df$barrio[i] == "Turo de la Peira - Can Peguera"|| 
               df$barrio[i] == "Verdum - Los Roquetes"|| 
               df$barrio[i] == "Vilapicina i la Torre Llobeta") {
      distritos[i] <- "Nou Barris"
    } else if (df$barrio[i]=='La Sagrada Familia' || 
               df$barrio[i] == "Eixample" || 
               df$barrio[i] == "L'Antiga Esquerra de l'Eixample" || 
               df$barrio[i] == "Sant Antoni" || 
               df$barrio[i] == "Dreta de l'Eixample" || 
               df$barrio[i] == "La Nova Esquerra de l'Eixample" || 
               df$barrio[i] == "el Fort Pienc") {
      distritos[i] <- "L'Eixample"
    } else if (df$barrio[i] == "Vila de Gracia" || 
               df$barrio[i] == "Camp d'en Grassot i Gracia Nova" || 
               df$barrio[i] == "Gracia" || 
               df$barrio[i] == "El Coll" || 
               df$barrio[i] == "La Salut" || 
               df$barrio[i] == "Vallcarca i els Penitents") {
      distritos[i] <- "Gracia"
    } else if (df$barrio[i] == "Horta-Guinarda" ||
               df$barrio[i] == "Can Baro" ||
               df$barrio[i] == "Carmel" ||
               df$barrio[i] == "El Baix Guinardo"||
               df$barrio[i] == "Guinarda" ||
               df$barrio[i] == "Horta"||
               df$barrio[i] == "La Font d'en Fargues"||
               df$barrio[i] == "La Teixonera"||
               df$barrio[i] == "La Vall d'Hebron"||
               df$barrio[i] == "Montbau"||
               df$barrio[i] == "Sant Geni­s dels Agudells") {
      distritos[i] <- "Horta"
    } else if (df$barrio[i] == "Les Corts"|| 
               df$barrio[i] == "La Maternitat i Sant Ramon"|| 
               df$barrio[i] == "Pedralbes") {
      distritos[i] <- "Les Corts"
    } else if (df$barrio[i] == "El Gotic" || 
               df$barrio[i] == "La Barceloneta" || 
               df$barrio[i] == "Ciutat Vella" || 
               df$barrio[i] == "El Raval" || 
               df$barrio[i] == "Sant Pere/Santa Caterina" || 
               df$barrio[i] == "El Born") {
      distritos[i] <- "Ciutat Vella"
    } else if (df$barrio[i] == "El Poble-sec" || 
               df$barrio[i] == "Sants-Montjuic") {
      distritos[i] <- "Sants-Montjuic"
    } else if (df$barrio[i] == "El Clot" || 
               df$barrio[i] == "El Besos i el Maresme" || 
               df$barrio[i] == "El Camp de l'Arpa del Clot"||
               df$barrio[i] == "El Poblenou"||
               df$barrio[i] == "La Vila Olimpica"||
               df$barrio[i] == "Diagonal Mar - La Mar Bella"||
               df$barrio[i] == "Glaries - El Parc"||
               df$barrio[i] == "La Verneda i La Pau"||
               df$barrio[i] == "Provencals del Poblenou"||
               df$barrio[i] == "Sant Marta­ de Provencals"
               ) {
      distritos[i] <- "Sant Martí"
    } else if (df$barrio[i] == "Sant Gervasi - Galvany"||
               df$barrio[i] == "El Putget i Farro"||
               df$barrio[i] == "Les Tres Torres"||
               df$barrio[i] == "Sant Gervasi - la Bonanova"||
               df$barrio[i] == "Sarria"||
               df$barrio[i] == "Sarria-Sant Gervasi") {
      distritos[i] <- "Sarriá"
    } else if (df$barrio[i] == "El Bon Pastor" ||
               df$barrio[i] == "El Congres i els Indians"||
               df$barrio[i] == "La Sagrera"||
               df$barrio[i] == "La Trinitat Vella"||
               df$barrio[i] == "Navas"||
               df$barrio[i] == "Sant Andreu"||
               df$barrio[i] == "Sant Andreu de Palomar") {
      distritos[i] <- "Sant Andreau"
  }
}
df$distritos <- distritos


df= df%>% mutate(tipo_habitacion=as.factor(tipo_habitacion),
                       camas=as.factor(camas),
                       distritos=as.factor(distritos),
                       Wifi=as.factor(Wifi),
                       TV=as.factor(TV),	 
                       Air_conditioning=as.factor(Air_conditioning),	
                       Elevator=as.factor(Elevator),	
                       Breakfast=as.factor(Breakfast),	
                       Pets_allowed=as.factor(Pets_allowed),	
                       Patio_or_balcony=as.factor(Patio_or_balcony),	
                       check_in_24_hs=as.factor(check_in_24_hs),	
                       grupo_habitacion=as.factor(ifelse(habitaciones>=0 & habitaciones<3,'Chica','Grande')),
                       grupo_banios=as.factor(ifelse(banios>=0 & banios<3,'Pocos','Muchos'))
                       
             )

set.seed(123)

n = nrow(df)
train_indices = sample(seq_len(n), size = round(0.7 * n))

df_final = df[train_indices, ]
df_test  = df[-train_indices, ]


df_table=df %>% select(distritos,tipo_habitacion,puntuacion,estancia_min,grupo_habitacion,puntuacion)


# Convertir el resumen a data frame para mejor manejo
resumen_df <- as.data.frame.matrix(summary(df_table))



#resumen_df[,-2] %>% select(distritos,tipo_habitacion,puntuacion,estancia_min,grupo_habitacion,puntuacion,precio_euros,Wifi,Air_conditioning)


#knitr::kable(resumen_df) %>% print()
# Crear una tabla bonita con kable
kable(resumen_df, format = "latex", booktabs = TRUE, row.names = FALSE) %>%
  kable_styling(latex_options = c("striped", "hold_position")) 
```

```{r warning=FALSE, echo=FALSE,tab.cap="Descripción de las variables utilizadas en el informe",fig.align='center', results = 'asis'}

df_table2=df %>% select(precio_euros,Wifi,Air_conditioning)

resumen_df2 <- as.data.frame.matrix(summary(df_table2))



#resumen_df[,-2] %>% select(distritos,tipo_habitacion,puntuacion,estancia_min,grupo_habitacion,puntuacion,precio_euros,Wifi,Air_conditioning)


#knitr::kable(resumen_df) %>% print()
# Crear una tabla bonita con kable
kable(resumen_df2, format = "latex", booktabs = TRUE, row.names = FALSE) %>%
  kable_styling(latex_options = c("striped", "hold_position")) 

```


\newpage

# Análisis exploratorio

Como parte de la estadística descriptiva se crearon gráficos donde se relacionan algunas de las variables explicativas con la variable de respuesta (precio en euros), estos graficos permiten obtener interpretaciones de las diferentes relaciones, pero es muy importante destacar que las interpretaciones obtenidas son parciales, debido a que a diferencia del modelo, en cada uno de los gráficos se representa el efecto de una variable sin tomar en cuenta las demás.

```{r message=FALSE,warning=FALSE,echo=FALSE,fig.cap="Histograma de la variable de respuesta Precio",results='asis', fig.align='center'}

h1=df%>%ggplot()+geom_histogram(aes(x=precio_euros)) +theme_bw() + theme (axis.title.y = element_blank()) + labs(x="Precio (en Euros)")
# Se "normalizan" más los datos con Log(Precio_euros)
h2=df%>%ggplot()+geom_histogram(aes(x=log(precio_euros))) +theme_bw()+ theme (axis.title.y = element_blank()) + labs(x="Log(Precio)")

h1/h2

```



```{r message=FALSE,echo=FALSE, warning=FALSE,fig.cap="Dispersión de Precio (en euros) por Distrito",results='asis', fig.align='center'}

ggplot(data=df_final) + geom_boxplot(aes(x=distritos,y=log(precio_euros),fill=distritos))+labs(y="Log(Precio)",x="Distritos",fill="Distritos") +theme_bw()  + theme (axis.title.x = element_blank(),axis.text.x = element_text(angle = 45,vjust = 0.5)) 

```

En el presente gráfico se puede observar la distribución de los datos y la relación entre los distritos y log(Precio). La mayoría de las cajas se encuentran superpuestas entre si, por lo que no se podría afirmar cual es el distrito que lleva a apartamentos con un log(Precio) más alto, pero si se pueden interpretar algunas diferencias entre los distritos, como que los apartamentos del distrito L'Eixample tienen un log(Precio) mayor que el distrito de Nou Barris. También se resalta la presencia de observaciones atípicas, que tienden a tener un log(Precio) más alto que las mayoría.


```{r message=FALSE,echo=FALSE, warning=FALSE,fig.cap="Dispersión de Precio (en euros) según la puntuación, por tipo de alojamiento",results='asis', fig.align='center'}

ggplot(data=df_final,aes(x=puntuacion,y=log(precio_euros),col=tipo_habitacion)) + geom_point(size=1) + xlab("Puntuación")+ ylab('Log(Precio)')  +theme_bw() + geom_smooth(method = 'lm',se = FALSE)

```

En el gráfico 3 se muestra a partir de un gráfico de dispersión la relación entre las diferentes combinaciones de las variables explicativas, puntuación y tipo de habitación, con la variable respuesta, log(Precio). Lo primero a destacar es que los puntos tienden a estar acumulados en la parte derecha del gráfico, teniendo en su mayoría una puntuación mayor a 60, por lo que permite interpretar que no existe ninguna relación entre puntuación y log(precio). Por otro lado también se puede observar que existe una relación muy marcada entre el tipo de habitación y la variable respuesta, los apartamentos enteros se encuentran en la parte derecha y superior del gráfico, es decir, que están relacionados con precios más altos, mientras que el resto se encuentran en el extremo inferior.

\newpage

# Metodología

## Selección de variables

A partir de las diferentes combinaciones de las variables explicativas se puede llegar a una gran cantidad de modelos que busquen predecir el precio, cada uno de estos llevará a una predicción diferente de el mismo. Uno de los problemas centrales es encontrar cual de todos estos modelos cumple mejor su objetivo. En este proyecto finalmente se decidió que 15 del total variables explicativas formaran parte del modelo incial.


```{r }
  
# Definimos la primer versión del modelo

mod0 <- lm(log(precio_euros) ~  distritos + tipo_habitacion+personas+ grupo_banios+ grupo_habitacion+estancia_min+puntuacion+TV+Wifi+Air_conditioning+Elevator+Breakfast+Pets_allowed+Patio_or_balcony+check_in_24_hs, data=df_final)

Anova(mod0)
summary(mod0)

```

## Diagnóstico

Luego de la limpieza de datos y estadística descriptiva se comenzó la etapa de diagnótico, esta etapa es imprescindible debido a que el cumplimiento de todos los supuestos sobre el modelo es el que permite afirmar que las inferencias realizadas son validas.
Entre estos supuestos se encuentran:

Multicolinealidad: en está prueba se busca que ninguna de las columnas de la matriz X sea "casi" combinación lineal de las demás. Cuando esto si sucede el número de condición aumenta, lo que lleva finalmente a que la inversa de X'X sea inestable. Esta inestabilidad es la que finalmente se busca evitar.

Linealidad: este supuesto se basa en la linealidad de la variable log(Precio) y cada una de las variables explicativas, si en el modelo no hay linealidad se presentarán problemas de correlación entre los residuos y variabilidad de los mismos. Para verificar el cumplimiento de este supuesto se realizó un análisis gráfico entre los Yˆ y εˆ, en el cual se busca no encontrar patrones.

Homoscedasticidad: se busca que el modelo sea homoscedastico, es decir, que la varianza de todos los residuos sea constante,se va a entender esto como que la varianza no depende de ninguna de las variables explicativas. Esta prueba se suele ver mediante gráficos que relacionan cada variable explicativa con la de respuesta y a partir de una prueba de hipótesis donde se busca no rechazar la hipótesis nula. 

Normalidad: se refiere a que los residuos deben tener una distribución normal, este supuesto es muy importante debido a que es el que luego permite realizar inferencias. Sin embargo en los modelos donde el tamaño de muestra es grande, como en este caso, la falta de normalidad de los residuos no generan repercusiones.

En las siguientes lineas del script se pusieron a prueba cada uno de los supuestos antes mencionados.



### Multicolinealidad

```{r echo=FALSE,results='asis',tab.cap="Valores de la prueb VIF"}
library(car)

X <- model.matrix(mod0)
XX <-t(X)%*%X
eigen_result <- eigen(XX) #valores y vectores propios de XX

# Obtener los valores propios
valores_propios <- eigen_result$values

#Número de condición ¿LO MOSTRAMOS?
kA <- sqrt(max(valores_propios)/min(valores_propios))
#print(kA)

vifvalues=data.frame(valor=vif(mod0))

vifvalues=vifvalues%>%arrange(valor)

kable(vifvalues, format = "latex", booktabs = TRUE,col.names = "Valor VIF") %>%
  kable_styling(latex_options = c("striped", "hold_position")) 

#RESOLVER: PONER EN TABLA PARA EL INFORME

```

Se comenzó evaluando el supuesto de multicolinealidad, para esto se calculó el número de condición, el cual dió 1711.793, es decir, existían problemas de multicolinealidad. Luego se calculó el VIF para cada una de las variables explicativas, todas tenían un VIF mayor a 1 pero menor a 5, por lo cual, no se pudo determinar cual es la variable que generó el problema del cumplimiento de este supuesto. De igual forma, esto no provocó grandes problemas debido a que se trabajó con un modelo con muchas variables cualitativas, lo cual hace que la evaluación de este supuesto no tenga mucho sentido. 

\newpage

### Linealidad 

```{r echo=FALSE,fig.cap="Gráfico de puntos de los residuos del modelo en función de los valores predichos", results='asis' }

res_ext<-rstudent(mod0) #residuos
res_int<-rstandard(mod0) #residuos
yhat<-fitted(mod0) #ygorro
#grafico

df_final$predichos <- yhat #agrego los residuos a la tabla
df_final$residuos <- res_ext #agrego los ygorro a la tabla
df_final$residuos_int <- res_int #agrego los ygorro a la tabla

ggplot(df_final, aes(x = predichos , y = residuos)) +
  geom_point(size=1) +  geom_hline(yintercept = 0) + labs(y="Residuos",x="Predichos") +theme_bw() 

```

Luego se siguió con el supuesto de linealidad, donde se realizó el grafico entre residuos y predichos. En dicho gráfico se puede observar que no existe ningun patrón, por lo cual se podría afirmar que se cumple el supuesto de linealidad. Esto se podría dar como una repercusión de la transformación logaritmica, debido a que esta permite solucionar casos donde la variable respuesta no presenta una relación lineal con una o más variables explicativas.


```{r eval=FALSE,echo=FALSE,fig.cap="Gráfico de puntos de los residuos del modelo en función de los valores predichos", results='asis' }

#PUNTO 6 TALLER
#distritos + tipo_habitacion+personas+ banios+ habitaciones+camas+estancia_min+puntuacion+TV+Wifi+Air_conditioning+Elevator+Breakfast+Pets_allowed+Pool+Patio_or_balcony+check_in_24_hs+Smart_lock

#RESOLVER: PREGUNTARLE AL PROFE
#QUE SIGNIFICAN ESTOS GRÁFICOS? ES PARA EL SUPUESTO DE LINEALIDAD? ES NECESARIO HACERLOS???
crPlot(mod0,"distritos")
crPlot(mod0,"tipo_habitacion")
crPlot(mod0,"grupo_habitacion")
crPlot(mod0,"estancia_min")

```


### Homoscedasticidad

Como ya se mencionó, los dos primeros supuestos diagnosticados son importantes pero no tanto para un modelo como el presente, por lo cual se centró la atención en diagnosticar los supuestos restantes, como la homoscedasticidad, donde a partir del test de BREUSCH-PAGAN se pudo observar que en el modelo inicial no se cumplía este supuesto. El p-valor dió muy bajo, lo que provocó que se rechazara H0. 

```{r results='asis',tab.cap="Resultados de la prueba de BREUSCH-PAGAN"}

bp=data.frame(breusch_pagan(mod0))
kable(bp, format = "latex", booktabs = TRUE,row.names = FALSE) %>%
  kable_styling(latex_options = c("striped", "hold_position")) 
```

### Normalidad

```{r fig.cap="Histograma de los Residuos Studentizados",results='asis', fig.align='center'}

ggplot() + geom_histogram(aes(x=rstudent(mod0)),bins = 100) + xlab("Residuos Studentizados")+  theme_bw() + theme (axis.title.y = element_blank()) 

#RESOLVER: VER SI SE PUEDE AGREGAR CAMPANA.

```

```{r}

ggplot(data = df_final, aes(sample = res_ext)) +
  stat_qq_band(fill = 2) +
  stat_qq_line(col = 2) +
  stat_qq_point() +
  xlab("Cuantiles teoricos")+
  ylab("Cuantiles empiricos")+theme_bw()


```


```{r}

ks.test(df_final$residuos_int, 'pnorm')

```
Otro supuesto importante es el de la normalidad, para evaluarlo se realizó un histograma y un QQ-Plot, en el primer gráfico se pudo observar que tenía forma de una campana simétrica (hay que resaltar que la forma del histograma está muy influenciada por el tamaño de los bins), en cambio en el segundo gráfico los puntos se encontraban fuera de la banda, es decir, el primer gráfico dio indicios de que si se cumplia el supuesto de normalidad pero el segundo mostraba que no. Para definir el cumpliento o no del supuesto se realizó la Prueba de Kolmogorov-Smirnov. En esta prueba se obtuvo un p-valor muy chico el cual llevó a que se rechace H0, esto concluyó que el supuesto de normalidad no se cumplió. 
Sin embargo, obtener el cumplimiento de este supuesto no fue de mucha importancia debido a la robustez que proporciona el Teorema Central del Límite cuando se trabaja con muchas observaciones.


### Atípicos

Por último se realizó el gráfico de la Distancia de Cook para observar si habían observaciones atípicas. Usualmente en este gráfico se hace la línea roja horizontal al nivel de 4/n, donde n es el número de observaciones, como en el modelo las observaciones eran muchas esta linea roja quedaba muy baja, haciendo referencia a que todas las osbervaciones eran atípicas, para poder interpretar mejor esto se decidió que la linea esté en el nivel de 4/500, en ese punto las observaciones atípicas terminan siendo las más diferentes.

```{r, echo=FALSE}

h_i <- influence(mod0)$hat
D_i <- cooks.distance(mod0)

df <- data.frame(i = 1:nrow(df_final),
                 h_i = h_i,
                 D_i = D_i)


ggplot(df, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/500, col = 2, linetype = 'dashed') +theme_bw()

```



```{r, echo=FALSE}

id_atipico = df %>% filter(D_i>(4/500))%>% arrange(desc(D_i)) %>% pull(i)

```


## Correción del modelo

A continuación se verán algunos de los cambios realizados en el modelo con respecto al cumplimiento de los principales supuestos junto con los nuevos resultados. Se comenzó eliminando los datos atípicos y creando un nuevo modelo sin tomarlos en cuenta.

```{r}
df_2=df_final[-id_atipico,]


mod1 <- lm(log(precio_euros) ~  distritos + tipo_habitacion+personas+ grupo_banios+ grupo_habitacion+estancia_min+puntuacion+TV+Wifi+Air_conditioning+Elevator+Breakfast+Pets_allowed+Patio_or_balcony+check_in_24_hs, data=df_2)

#para "vichar"
Anova(mod1)
summary(mod1)

#distritos(Gracia)              0.1495579
#exp(0.1495579)=1.161834

#"Gracia es 16% más caro que el grupo de referencia DEJANDO TODO DEMAS CONSTANTE" TOMAR SOLO ALGUNAS VARIABLES.

#RESOLVER: PONER EN TABLA
summary(mod0)$sigma
summary(mod1)$sigma

summary(mod0)$r.squared
summary(mod1)$r.squared


##  UNA VEZ DEFINIDO EL MODELO, PODEMOS HACER UN SPLIT DE DATOS 70/30 PARA ENTRENAR Y TESTEAR.

# p-valor de grupo_habitación alto, ¿está relacionado con el grupo de referencia? ¿Habrá que sacar la variable?



```

```{r}
h_i <- influence(mod1)$hat
D_i <- cooks.distance(mod1)

df_cook <- data.frame(i = 1:nrow(df_2),
                 h_i = h_i,
                 D_i = D_i)


ggplot(df_cook, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/500, col = 2, linetype = 'dashed') +theme_bw()


id_atipico_2 = df_cook %>% filter(D_i>(4/500))%>% arrange(desc(D_i)) %>% pull(i)

df_2[-id_atipico_2,]

```

```{r}
df_3=df_2[-id_atipico_2,]


mod2 <- lm(log(precio_euros) ~  distritos + tipo_habitacion+personas+ grupo_banios+ grupo_habitacion+estancia_min+puntuacion+TV+Wifi+Air_conditioning+Elevator+Breakfast+Pets_allowed+Patio_or_balcony+check_in_24_hs, data=df_3)

#para "vichar"
Anova(mod2)
summary(mod2)

#distritos(Gracia)              0.1495579
#exp(0.1495579)=1.161834

#"Gracia es 16% más caro que el grupo de referencia DEJANDO TODO DEMAS CONSTANTE" TOMAR SOLO ALGUNAS VARIABLES.

#RESOLVER: PONER EN TABLA
summary(mod0)$sigma
summary(mod1)$sigma
summary(mod2)$sigma

summary(mod0)$r.squared
summary(mod1)$r.squared
summary(mod2)$r.squared
```


```{r}
h_i <- influence(mod2)$hat
D_i <- cooks.distance(mod2)

df_cook_2 <- data.frame(i = 1:nrow(df_3),
                 h_i = h_i,
                 D_i = D_i)


ggplot(df_cook_2, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/500, col = 2, linetype = 'dashed') +theme_bw()

#no seguir

```


# Resultados

NO LOGRAMOS QUE EL SUPUESTO DE HOMOSCEDASTICIDAD SE CUMPLIERA

ACÁ IRÍA LAS PREDICCIONES Y LAS INTERPRETACIONES DEL MODELO

```{r}

df_test$predicciones = predict(mod2,newdata = df_test)

results=df_test %>% select(precio_euros,predicciones)%>%mutate(precio_predic=exp(predicciones),
                                          delta_precio=round(precio_euros-exp(predicciones),2))

y_prom=mean(df_test$precio_euros)


num=sum((results$delta_precio)**2)

den=sum((df_test$precio_euros-y_prom)**2)

1-(num/den)


summary(mod2)
```






# Conclusiones

(((Luego de realizadas las predicciones, se logró concluir que el modelo es funcional según las pruebas realizadas aunque tal vez creemos que se podría seguir mejorando ya sea agregando nuevas variables que puedan ser relevantes y que no estén en los datos iniciales.)))

Luego de realizadas las pruebas y predicciones se logró concluir que el modelo si es funcional y cumple con su objetivo, sin embargo, hay varios supuestos que no se cumplen lo cual lleva a pensar que es un modelo que todavía puede ser mejorado, ya sea agregando variables que sean relevantes que no estuvieran incluidas en los datos iniciales o trabajando de diferente forma con las presentes.

“Todos los modelos son incorrectos, pero algunos son útiles” George Edward Pelham Box

# Bibliografía

Carmona, Francesc (2003). Modelos Lineales (notas de curso). Departament d’Estad´ıstica.
Farraway, Julian (2014). Linear Models with R, second edition. Chapman Hall/CRC.
Rencher, Alvin y Bruce Schaalje (2008). Linear Models in Statistics, second edition. John Wiley Sons, Inc.
Peña, Daniel (2010). Regresi´on y Dise˜no de Experimentos. Alianza Editoria
https://es.wikipedia.org/wiki/Distritos_de_Barcelona

